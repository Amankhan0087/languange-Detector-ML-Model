Identify the language of any text using ML, NLP & Google Translate API
<p align="center"> <img src="https://img.shields.io/badge/Python-3.10-blue?style=for-the-badge" /> <img src="https://img.shields.io/badge/NLP-Project-green?style=for-the-badge" /> <img src="https://img.shields.io/badge/Machine%20Learning-Scikit--Learn-orange?style=for-the-badge" /> <img src="https://img.shields.io/badge/API-Google%20Translate-red?style=for-the-badge" /> <img src="https://img.shields.io/badge/Status-Completed-success?style=for-the-badge" /> </p>

ğŸ“Œ Project Overview

This project is a complete Machine Learning + Natural Language Processing (NLP) pipeline designed to detect the language of any given text input.
It uses:

NLP preprocessing techniques

Feature engineering (TF-IDF or CountVectorizer)

Machine Learning classification model

Google Translate API for additional validation

The model can successfully identify multiple languages, making it ideal for chatbots, translation tools, customer service automation, and AI applications.

ğŸ§  Key Features

âœ” Detect the language of any input text
âœ” End-to-end ML training process
âœ” NLP preprocessing pipeline
âœ” Dataset cleaning + feature extraction
âœ” Model evaluation + accuracy score
âœ” Google Translate API integration
âœ” Highly scalable & customizable

ğŸ› ï¸ Tech Stack
Category	Tools / Libraries
Language	Python
ML Library	Scikit-Learn
NLP	NLTK / SpaCy / TF-IDF
API	Google Translate (googletrans / googletrans==4.0.0-rc1)
Notebook	Jupyter Notebook
Visualization	Matplotlib & Seaborn

ğŸ“‚ Project Structure

language-detection-project/
â”‚â”€â”€ data/
â”‚   â””â”€â”€ dataset.csv
â”‚
â”‚â”€â”€ notebooks/
â”‚   â””â”€â”€ Language_Detection.ipynb
â”‚
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ model_training.py
â”‚   â”œâ”€â”€ prediction.py
â”‚
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ .gitignore


ğŸš€ How It Works
1ï¸âƒ£ Data Cleaning

Remove punctuation

Lowercase conversion

Remove numbers

Tokenization

Stopword removal

2ï¸âƒ£ Feature Extraction

TF-IDF Vectorization

Converts text â†’ numerical vectors

3ï¸âƒ£ Model Training

Logistic Regression / Naive Bayes / SVM

Trained on multilingual text samples

4ï¸âƒ£ Prediction Pipeline

Input â†’ Preprocessing â†’ Vectorization â†’ Model â†’ Language Label

5ï¸âƒ£ External API Integration

Google Translate API used to validate predictions or auto-translate text

ğŸ“Š Model Performance

High accuracy (depending on dataset)

Strong performance on short & long sentences

Works across different writing styles

Add your score like this:

Accuracy Achieved: 94%
Languages Supported: English, French, Spanish, German, Urdu, Hindi, Portuguese, Italian, etc.

ğŸ“¸ Project Visuals

You can add these once you upload the images:

![NLP Pipeline](assets/nlp_pipeline.png)
![Confusion Matrix](assets/confusion_matrix.png)
![TF-IDF Visualization](assets/tfidf_plot.png)


ğŸ§ª How to Run the Project
1ï¸âƒ£ Clone the Repository

git clone https://github.com/YOUR-USERNAME/language-detection-project.git

2ï¸âƒ£ Install Dependencies

pip install -r requirements.txt

3ï¸âƒ£ Open Notebook

jupyter notebook

4ï¸âƒ£ Run the Model

Inside the notebook:

predict_language("Bonjour, comment allez-vous?")

ğŸŒŸ Future Improvements

ğŸ”¹ Add Deep Learning (LSTM / Transformers)
ğŸ”¹ Build a Streamlit web app for real-time language detection
ğŸ”¹ Deploy model as an API
ğŸ”¹ Add more languages
ğŸ”¹ Improve dataset diversity

ğŸ‘¨â€ğŸ’» Author

Aman Khan
Machine Learning â€¢ NLP â€¢ Data Science
ğŸ”— GitHub: https://github.com/Amankhan0087


ğŸ”— LinkedIn: https://www.linkedin.com/in/aman-khan-data-scientist/
ğŸ¤ Contributions

Contributions, issues, and feature requests are welcome!
Feel free to â­ star the repo if you like it.
